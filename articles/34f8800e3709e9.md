---
title: "SlickのバルクインサートSQLをshapelessで自動生成"
emoji: "⛽"
type: "tech"
topics: ["scala", "slick", "sql", "関数型プログラミング"]
published: true
---

# はじめに

[Slick](https://scala-slick.org/)はScalaでよく利用されているデータベース用のライブラリーであり、SQLのようなシンタックスをScalaの言語内DSLとして提供する。ただSlickはコレクションとなった複数の同一型のデータのインサートが低速であることが知られている。たとえば[@taket0ra1](https://twitter.com/taket0ra1)さんの記事[Slick（MySQL）でBulk Upsertを実装する](https://zenn.dev/taketora/articles/7ececc752eee2c)では次のような方法で高速な`INSERT`クエリーを自作する方法が紹介されている。

```scala
SimpleDBIO { session =>
  val statement = session.connection.prepareStatement(sqlStatement)
  books.zipWithIndex.foreach {
    case (row, i) =>
      val rowSize = 3
      val offset  = i * rowSize
      statement.setInt(1 + offset, row.id)
      statement.setString(2 + offset, row.name)
      statement.setString(3 + offset, row.author)
  }
  statement.executeUpdate()
}
```

このコードではまずSlickの機能でプリペアードステートメントな`INSERT`クエリー[^prepared_statement]を取得し、それに対してバルクで挿入したいデータ`books: Seq[Book]`をループで回してプレースホルダーに対応するインデックスに`row.id`や`row.name`などのデータを挿入している。
最終的には筆者の実装もこれと同じテクニックを利用して高速化を達成するが、一方でこの`setInt`や`setString`のような低レベル[^low_level]な関数を直接プログラマーが記述するため次のような問題が考えられる。

- インデックスを間違えたりテーブル定義上`int`なカラムに`setString`すればランタイムエラーになる
- テーブル定義や`Book`のデータ構造が変化した場合には、このクエリー生成部分も修正しなければランタイムエラーとなる

これらのことからSlick標準の`++=`と比べて効率はよいが一方で保守性は低下したと言わざるを得ない。
この記事ではこのような低レベルなクエリーの生成を[shapeless](https://github.com/milessabin/shapeless)を利用して完全に自動化し、人間が危険なインデックス管理や`setString`のメソッド選択をする余地を消去した。さらに[shapeless-3](https://github.com/typelevel/shapeless-3)というScala 3版のshapelessを利用してScala 3に対応してある[^slick_scala3]。また、最後に詳しく述べるがSlickの`++=`と比べて10倍程度の高速化が達成された。
この記事で紹介するコードの完全なものは下記のGitHubリポジトリーに置かれている。

- https://github.com/y-yu/slick-bulk-insert

この記事について質問やコメントなどがあれば気軽に連絡してほしい。

[^prepared_statement]: この記事にはあまり関係ないが、プリペアードステートメント（Prepared statement）とはSQLのうち、IDなどのデータが入りうる部分を`printf`の`%s`のようなフォーマット指定子のように渡してやることで、外部の文字列によりプログラマーが意図しないSQLの意味論を変化させるような攻撃（SQLインジェクション）を困難にするために用いられる技術である。

[^low_level]: 念のため述べておくと、この記事では「具体的な機械の実装に近い」とか「抽象度が低い」といった意味合いで低レベルという語を利用するのであって、プログラムの善し悪しとは関係ない。

[^slick_scala3]: 現在SlickはScala 3対応が完了していないが、SlickのPRからコードを拝借することによって無理やりScala 3でもSlickが動作するようにした。したがってSlickがこのあとScala 3対応した場合、直ちにこのプログラムを利用できる。

# 型クラス`BulkInsertable[A]`

まずは、最初に述べたようなデータベースに保存されうる`Book`のような、とある型`A`がバルクインサートできることを示す型クラス`BulkInsertable`を次のように定義する。

```scala:BulkInsertable.scala
trait BulkInsertable[A] {
  def set(statement: PreparedStatement, a: A): State[Int, Unit]

  def parameterLength: Int
}
```

`BulkInsertable`には2つの機能がある。

1. `set` …… プリペアードステートメントに型`A`の値（= `a`）をセットする
2. `parameterLength` …… 型`A`に必要なプレースホルダーの個数

まず（1）の`set`については低レベルな関数と述べた`setString`や`setInt`の抽象化版ということになる。ただしこの関数はインデックスを取らず、代わりに返り値の型がステートモナド（`State`）になっている。このステートモナドの状態が`Int`であり、ここでインデックスを管理している。
そして次の`parameterLength`はパラメータの数で、たとえば次のようなケースクラス`Book`について考える。

```scala
case class Book(id: Int, name: String, author: String)
```

これをインサートするSQLは次のようになる。

```sql
INSERT INTO book (`id`,　`name`, `author`) VALUES  ('1', 'MyBook1', 'Yamada')
```

したがって`Book`パラメーター数は`3`となる。これは`(?, ?, ?)`のようなプリペアードステートメントのプレースホルダーを生成するために用いる。`Book`の場合はこれでいいとして、次のようなやや複雑な型についても考える。

```scala
case class BookWithOwner(ownerName: String, book: Book)
```

この`BookWithOwner`を1つのテーブルに押し込んだと考えると、`parameterLength`は$1 + 3 = 4$を返す必要がある[^normalize]。

[^normalize]: このような場合、リレーショナルデータベースでは通常`owner`テーブルと`book`テーブルを別々に作るとは思う。さらにいえば、ScalaやDDDなどの慣例上もデータモデルとドメインモデルを別々にするといった理由でデータモデルにあたるSlickのデータ型でこのような複雑な記述をするとも考えにくいとは思う。

# `BulkInsertable`インスタンス定義

次に型クラス`BulkInsertable`のインスタンスを定義する。

## `SetParameter`を用いたプリミティブ型のインスタンス

とりあえずプリミティブな`Int`型などについての`BulkInsertable[Int]`は`setInt`を利用して定義すればよさそうではあるが、Slickは便利なことに`SetParameter[A]`という型クラスを持っており、これを使えばプリミティブ型については次のように簡単に定義することができる。

```scala:BulkInsertableInstances.scala
implicit def setParameterInstance[A](implicit
  setParameter: SetParameter[A]
): BulkInsertable[A] =
  new BulkInsertable[A] {
    def set(statement: PreparedStatement, a: A): State[Int, Unit] =
      State { s =>
        val positionedParameters = new PositionedParameters(statement)
        positionedParameters.pos = s - 1
        (s + 1, setParameter(a, positionedParameters))
      }

    def parameterLength: Int = 1
  }
```

Slickの`SetParameter`は`PositionedParameters`という`PreparedStatement`に加えて現在のインデックスを状態として持つクラスを利用している。しかし今回の実装では、暗黙的な状態を利用したくなかったのでステートモナドを利用することとし、`PositionedParameters`は`setParameter`が済んだら都度捨てることとした。
また`parameterLength`については常に`1`となっている。これはプリミティブな型でプレースホルダーがいらないということはないので`1`とした。

## Scala 2のジェネリックインスタンス

もはやshapelessはScalaのマクロを利用して、ケースクラスのようなユーザー（= プログラマー）が定義したデータ構造を`HList`と呼ばれる長さが変化するタプルのような構造に変換して処理できる[^generic_programming_info]。たとえば先ほどのデータ構造`Book`は次のような定義であった。

```scala
case class Book(id: Int, name: String, author: String)
```

これは次のような`HList`に対応する。

```scala
Int :: String :: String :: HNil
```

このようにshapelessを利用すると任意のケースクラスをこのような対応する`HList`に変換したり、逆にこの`HList`から元の型を復活させたりする機能を提供する[^generic_programming]。したがってまずは`HList`に関するインスタンスを次のように定義する。

```scala:scala-2/BulkInsertableGenericInstances.scala
implicit val hNilInstance: BulkInsertable[HNil] = new BulkInsertable[HNil] {
  def set(statement: PreparedStatement, a: HNil): State[Int, Unit] =
    State(s => (s, ()))

  def parameterLength: Int = 0
}

implicit def hConsInstance[H, T <: HList](implicit
  head: BulkInsertable[H],
  tail: BulkInsertable[T]
): BulkInsertable[H :: T] = new BulkInsertable[H :: T] {
  def set(statement: PreparedStatement, a: H :: T): State[Int, Unit] =
    for {
      _ <- head.set(statement, a.head)
      _ <- tail.set(statement, a.tail)
    } yield ()

  def parameterLength: Int = head.parameterLength + tail.parameterLength
}
```

まず`HNil`のケースでは何も生成する必要はないし、クエリーにも反映されないことからインデックスの更新も何もせずに終了する。一方で`::`のケースについて見ていく、まず`set`メソッドでは`head`/`tail`に分解してそれぞれ`set`を呼び出している。`set`の返り値はステートモナドなので、このように`for`で繋ぐことでインデックス更新を伝搬する。また`parameterLength`は`head`/`tail`のそれぞれを足し算すればOKである。
最後に型`A`から対応する`L <: HList`へ変換したり戻したりする部分を次のように定義して終了となる。

```scala:scala-2/BulkInsertableGenericInstances.scala
implicit def hListInstance[A, L <: HList](implicit
  gen: Generic.Aux[A, L],
  hList: Lazy[BulkInsertable[L]]
): BulkInsertable[A] = new BulkInsertable[A] {
  def set(statement: PreparedStatement, a: A): State[Int, Unit] =
    hList.value.set(statement, gen.to(a))

  def parameterLength: Int = hList.value.parameterLength
}
```

ここで`gen: Generic.Aux[A, L]`とは、型`L <: HList`が型`A`に対応する`HList`であれば値の検索に成功するような`implicit`パラメーターになっている。そしてこの`gen`を利用して`a`を`HList`にしたり戻したりすればよい。

[^generic_programming]: 記事には直接関係ないが、このようなプログラミング手法のことを _datatype-generic programming_ やあるいは _generic programming_ と呼ぶ。

[^generic_programming_info]: この記事でも軽くは解説するが、もしshapelessを用いたプログラミングをより詳しく知りたい場合、拙著となるが[“ダミー値”を自動で作成する型クラス](https://qiita.com/yyu/items/cc8515339f55476b46b6)で詳しく解説したのでそちらを参照してほしい。

## Scala 3のジェネリックインスタンス

まず言っておくこととして、Scala 2版のshapelessとScala 3版のshapeless-3は全く互換性がなく、そもそもScala 3がリリースされてまだ時間が経ってないためかshapeless-3は機能が大幅に足りていない。なので同じような名前のライブラリーではあるが次のようにコードの見た目は全く違うものとなる。

```scala
trait BulkInsertableGenericInstances { self: BulkInsertableInstances =>
  implicit def bulkInsertableGenInsance[A](implicit inst: K0.ProductInstances[BulkInsertable, A]): BulkInsertable[A] =
    new BulkInsertable[A] {
      def set(statement: PreparedStatement, a: A): State[Int, Unit] = {
        inst.foldLeft(a)(State(s => (s, ())): State[Int, Unit]) {
          [t] => (acc: State[Int, Unit], bk: BulkInsertable[t], x: t) =>
            acc >> bk.set(statement, x)
        }
      }

      def parameterLength: Int = inst.unfold(0) {
        [t] => (acc: Int, bk: BulkInsertable[t]) =>
          // The second value of this tuple is never used so it's safe for now.
          (acc + bk.parameterLength, Some(null.asInstanceOf[t]))
      }._1
    }
}
```

`inst: ProductInstances[BulkInsertable, A]`は、さきほどScala 2側で説明したような`A`に対応するような`HList`が見つかった場合に`inst`という値が得られる。しかしScala 2とは違ってshapeless-3では`HList`のような`A`に対応する具体的な構造にアクセスできず、代わりに`inst`が`foldLeft`や`map`のようなリストに対する操作を提供する。
`set`に関してはこの`inst`を用いて`A`を`foldLeft`で回せばOKである[^flatMap]。一方で`parameterLength`では`set`と違って、型`A`の値を得られないため次の`unfold`という入力した関数の返り値の2番目が`None`にならない限り`inst`をループしてくれる機能を利用する。

```scala
inline def unfold[Acc](i: Acc)(
  f: [t] => (Acc, BulkInsertable[t]) => (Acc, Option[t])
): (Acc, Option[T])
```

本来`unfold`は最終的に型`A`の値を作りだすための機能であり、`None`が出現した時点でループを終了してしまう。今回の用途では型`A`の値を作るつもりはないが、一方で`inst`が持つ全ての`BulkInsertable[t]`についてそれの`parameterLength`を足し算する必要があり、途中でループを止められては上手くいかない。そこで強引ではあるが`Some(null.asInstanceOf[t])`で`unfold`を止めないようにしつつ、`acc`に各要素の`parameterLength`を足し算している。当然`unfold`の結果の`_2`へアクセスすれば`NullPointerException`などのランタイムエラーが生じる危険があるため、直ちに`_1`を取得してして危険な`_2`を葬っておく。

[^flatMap]: ちなみに`acc >> bk.set(statement, x)`とは`acc.flatMap(_ => bk.set(statement, x))`と同じである。

## 未定義な`Coproduct`インスタンス

実はここまでの紹介にあるジェネリックなインスタンスは片手落ちである。先に述べたようなケースクラス`Book`のような型の“積”は`HList`のような方法で対処できるものの、次のような型の“和”には対処できない。

```scala
sealed abstract class Color(val value: String)

case object Red extends Color("red")
case object Blue extends Color("blue")
case object Green extends Color("green")
```

結論から説明すると`BulkInsertable`はこのような型の和に対するインスタンスをあえて自動生成しない。つまり、もしプログラマーが特に手動で何もせず`Color`のようなデータモデルを`BulkInsertable`で処理しようとするとコンパイルエラーとなる。その理由を説明するために、別の型の和である次の例についても考えてみる。

```scala
sealed trait DeviceType

case class IOS(version: String, isIPad: Boolean)
case class Android(version: String, vender: String, isPixel: Boolean)
```

この`DeviceType`は`IOS`と`Android`の和となっているが、それぞれで持っているフィールドの数や型が異なる。このようなデータをどのようにテーブルへ詰めこむかを自動的に判断するのは難しい。したがってこのような`DeviceType`を持つようなデータモデルのインスタンスは必要ならプログラマーが手動で定義することとして、shapelessを使った自動的な生成は行わない。

# BulkInsertableからの`INSERT`クエリー作成

あとはここから実際のクエリーを組み立てればよい。下記の`bulkInsert`はバルクインサートしたいデータを受けとり、実際にインサートした個数を`DBIO[Int]`の型で返す。

```scala:BulkInsert.scala
trait BulkInsert[A] {
  protected def tableQuery: TableQuery[? <: Table[A]]

  def bulkInsert(dms: Seq[A])(implicit
    bulkInsertable: BulkInsertable[A]
  ): DBIO[Int] = dms match {
    case Nil =>
      DBIO.successful(0)

    case h +: ts =>
      SimpleDBIO { session =>
        val placeholder = (1 to bulkInsertable.parameterLength).map(_ => "?").mkString("(", ",", ")")
        val placeholders = (1 until dms.length).map(_ => placeholder)
        val sql = (tableQuery.insertStatement +: placeholders).mkString(",")
        val statement = session.connection.prepareStatement(sql)

        ts
          .foldLeft(bulkInsertable.set(statement, h)) { (acc, dm) =>
            bulkInsertable.set(statement, dm) >> acc
          }
          .run(1)
          .value

        statement.executeUpdate()
      }
  }
}
```

まずは`INSERT INTO table_name`のようなSQLを生成するためにSlickの`tableQuery`を抽象メンバーとして持っておく。
`bulkInsert`はSlickの`++=`と同様に`Seq[A]`を引数に取る。この関数は引数のシーケンスが`Nil`の場合とそうでない場合に場合分けしている。この理由は次のようになる。

- Slickが生成する`tableQuery.insertStatement`にはデフォルトで1つのプレースホルダーが入っているため、`Nil`の場合はデータベースへの問い合わせができないし、実際する必要がない
    - したがって`DBIO.successful(0)`で終了する
- また`h +: ts`のケースでは実際にSQLを組み立てるが、そのあと`foldLeft`を利用している。`foldLeft`は初期値が必要なので、そこに`h`を利用できて便利である

このときプレースホルダーの組み立てに`parameterLength`を利用し、あとは`foldLeft`で`set`しながらステートモナドを合成していけばプリペアードステートメントに適切な値を入力できる。

# SlickのScala 3対応

現在リリースされているSlick 3.3.3はScala 3対応されておらず、Scala 2のマクロでコンパイルエラーとなってしまう。具体的には`TableQuery`がマクロとなっており問題になるので、[SlickのPR #2187](https://github.com/slick/slick/pull/2187)にあるScala 3対応の`TableQuery`を持ってきてScala 3の場合にのみ上書きするようにして無理やり動作させる。#2187の`TableQuery`からは多少改変したが、正直これについては適当いじってはコンパイルを繰り返し、コンパイルが完全に通るまでにやっただけという感じなので、詳細は下記のコードを読んでほしい。

- https://github.com/y-yu/slick-bulk-insert/blob/master/core/src/test/scala-3/slick/Scala3CompatTableQuery.scala

とにかくこのように定義した`Scala3CompatTableQuery`をScala 3側のソースコードフォルダーに設置しておく。

```scala:scala-3/Scala3CompatTableQuery.scala
trait Scala3CompatTableQuery {
  inline def TableQuery[E <: AbstractTable[_]]: TableQuery[E] = ${ TableQueryImpl.applyExpr[E] }
}
```

一方でScala 2側には同名だが実装が空なトレイトを作っておけばよい。

```scala:scala-2/Scala3CompatTableQuery.scala
trait Scala3CompatTableQuery
```

そして使うところでこの`Scala3CompatTableQuery`を継承すると無事にScala 3ではSlickのScala 2のマクロが上書きされて利用されなくなりコンパイルエラーを回避できる。

```scala:UserTestDAO.scala
object UserTestDAO extends BulkInsert[UserDataModel] with Scala3CompatTableQuery {
  private val databaseConfig: DatabaseConfig[JdbcProfile] =
    DatabaseConfig.forConfig("testMySQL")

  override protected val profile = databaseConfig.profile

  import profile.api.*

  // ......
}
```

# ベンチマーク

ベンチマークは次のテーブルに今回作成した`bulkInsert`メソッドとSlickの`++=`でデータを10,000件インサートしてはその都度テーブルの内容を全て消去するという操作を10回行って平均を取るという方法にした。
Slickで利用するデータモデルと利用したテーブルは次のようになる。

```scala:UserDataModel.scala
case class UserDataModel(
  id: Int,
  name: Option[String],
  info: UserInfoDataModel,
  createdAt: Date
)

case class UserInfoDataModel(
  height: Double,
  weight: Double
)
```

```sql
mysql> SHOW CREATE TABLE users\G
*************************** 1. row ***************************
       Table: users
Create Table: CREATE TABLE `users` (
  `id` int NOT NULL,
  `name` text,
  `height` double NOT NULL,
  `weight` double NOT NULL,
  `created_at` date NOT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci
```

そしてベンチマークコードは[JMH](https://github.com/openjdk/jmh)を用いて次のようになっている。

```scala:Benchmarks.scala
@State(Scope.Thread)
@BenchmarkMode(Array(Mode.SingleShotTime))
@OutputTimeUnit(TimeUnit.MILLISECONDS)
@Warmup(iterations = 2)
@Measurement(iterations = 10)
@Fork(value = 1, warmups = 1)
class Benchmarks {
  val num = 10000
  val dms: Seq[UserDataModel] = createDataModels(num)

  @Setup(Level.Trial)
  def setupTrial(): Unit = {
    UserTestDAO.dropTableIfExists()
    UserTestDAO.createTable()
  }

  @TearDown(Level.Iteration)
  def tearIteration(): Unit = {
    UserTestDAO.delete()
  }

  @Benchmark
  def benchSlickInsertAllJmh(): Unit = {
    UserTestDAO.addAll(dms)
  }

  @Benchmark
  def benchBulkInsertJmh(): Unit = {
    UserTestDAO.run(UserTestDAO.bulkInsert(dms))
  }
}
```

本当はデータベースサーバーとScalaアプリケーションサーバーを別々に用意して実験したほうがいいが、そういう環境を用意できなかった。多少雑にはなるがGitHub ActionsのDockerでMySQL 8を動作させ、同じインスタンスでsbtで起動したベンチマークを動作させたところ、次のような[結果](https://github.com/y-yu/slick-bulk-insert/actions/runs/2173457651)となった。

- Scala 2
    ```
    [info] Benchmark                          Mode  Cnt     Score     Error  Units
    [info] Benchmarks.benchBulkInsertJmh        ss   10   254.737 ±  55.462  ms/op
    [info] Benchmarks.benchSlickInsertAllJmh    ss   10  2353.399 ± 129.191  ms/op
    ```
- Scala 3
    ```
    [info] Benchmark                          Mode  Cnt     Score    Error  Units
    [info] Benchmarks.benchBulkInsertJmh        ss   10   294.616 ± 53.436  ms/op
    [info] Benchmarks.benchSlickInsertAllJmh    ss   10  2534.799 ± 88.160  ms/op
    ```

約8〜9倍程度の高速化となっており、場合によっては10倍程度スコアに差がつくこともある。

# まとめ

以前からSlickの`++=`は性能が悪いことは議論されていた。どのようにすると高速になるのかは目処がたってなかったが、@taket0ra1さんの記事でやり方が明らかとなったので今回それを自動化した。今後はプロダクションのコードにこれを導入してより実際のアプリケーションに近い形で性能評価を進めたい。
この記事の内容とはやや関係ないが、そもそも今から新規のScalaアプリケーションでSlickを採用するべきかどうかであったり、あるいはSlickも今後利用するべきかというと微妙ではある。しかし現状、SlickはLightbend社がメンテナンスしているといったこともあって利用者は一定数いると考えられ、自分も含めて直ちにSlickから脱却できるのかというとそれは難しい。

# 謝辞

この記事を書くにあたって、[@xuwei-k](https://twitter.com/xuwei_k)さんには次のような様々な情報を頂いたので感謝したい。

- Slickの`SetParameter`について
- shapeless-3の情報
- SlickのScala 3対応方法

# 参考文献

- [Slick（MySQL）でBulk Upsertを実装する](https://zenn.dev/taketora/articles/7ececc752eee2c)
- [Slick 3.0 bulk insert or update (upsert)](https://stackoverflow.com/questions/35001493/slick-3-0-bulk-insert-or-update-upsert)
